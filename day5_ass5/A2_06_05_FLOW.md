# A2_06_05 — Program Flow, Behaviour & Viva Questions

This document describes the program flow, expected behaviour, verification notes and viva questions for `question.c` (Assignment 5 — Threads, Synchronization & System V shared memory). The implementation spawns three worker threads that compute A, B and C for randomly generated pairs (X, Y) stored in a System V shared memory segment.

## Quick summary

- Purpose: Create N random pairs (X,Y) and compute for each pair:
  - A = X * Y
  - B = 2*X + 2*Y + 1
  - C = B / A (floating point; 0.00 if A == 0)
- IPC: System V shared memory (`shmget`, `shmat`, `shmdt`, `shmctl`).
- Concurrency: three POSIX threads (`pthread_create`) with a `pthread_mutex_t` and `pthread_cond_t` in shared memory to synchronize phases.
- Execution: `gcc question.c -lpthread` then `./a.out N` where 1 <= N <= 10.

## Inputs & outputs

- Input: single integer N (number of pairs). Accepts 1..10.
- Output: Tabular text output printed by the parent after all computations completed, e.g.:

```
Pairs(X,Y) |  A  |  B  |   C
-------------------------------
(6, 9)    | 54 | 31 | 0.57
(1, 4)    |  4 | 11 | 2.75
(3, 0)    |  0 |  7 | 0.00
(7, 5)    | 35 | 25 | 0.71
(4, 4)    | 16 | 17 | 1.06
```

## High-level program flow

1. Parse and validate the command-line argument `N` (1..10). If invalid, print usage and exit.
2. Create a System V shared memory segment of size `sizeof(Shared)` using a fixed key (1234) and attach it.
3. Initialize the `Shared` structure in that segment:
   - `n = N`, `idx = 0`, `phase = 0`, `exit_flag = 0`, `done[] = {0,0,0}`.
   - Initialize `pthread_mutex_t mutex` and `pthread_cond_t cond` inside shared memory via `pthread_mutex_init` / `pthread_cond_init` (default attributes).
4. Generate `N` random pairs (X,Y) and populate `sh->pairs[i].x` and `.y` (seeded via `srand(time(NULL))`).
5. Create three threads:
   - `thread_a`: waits for `phase == 0` and computes `A = X*Y` for `sh->pairs[idx]`, sets `done[0]=1`, signals condition variable.
   - `thread_b`: waits for `phase == 1` and computes `B = 2*X + 2*Y + 1`, sets `done[1]=1`, signals condition variable.
   - `thread_c`: waits for `phase == 2` and computes `C = B / A` (or 0.0 when A==0), sets `done[2]=1`, signals condition variable.
6. Parent thread loops for each pair `i` from 0 to N-1:
   - Acquire mutex, set `idx = i`, set `phase = 0`, reset `done[]` to zero, broadcast cond to wake workers.
   - Wait for `done[0]` to become true (worker A finished), set `phase = 1`, broadcast cond.
   - Wait for `done[1]`, set `phase = 2`, broadcast cond.
   - Wait for `done[2]`, then release mutex and proceed to next pair.
7. After processing all pairs, set `exit_flag = 1`, broadcast cond to wake workers and have them exit their loops; join worker threads.
8. Parent prints the results table, sleeps 10 seconds (gives time to run `ipcs -m`), then destroys synchronization objects, detaches and removes the shared memory segment.

## Synchronization contract and invariants

- Shared fields protected by `sh->mutex` while being read/modified by any thread.
- Condition variable `sh->cond` used to signal phase changes and worker completion.
- The `phase` integer defines the phase expected by each worker:
  - phase=0: thread_a runs
  - phase=1: thread_b runs
  - phase=2: thread_c runs
- The `done[]` flags are set by worker threads to indicate completion for the current `idx`.
- `exit_flag` tells each worker to exit their loop and terminate cleanly when set by the parent.

## Design notes & rationale

- The parent drives the pipeline: it sets `idx` and `phase` and waits on `done[]`. This avoids race conditions because the parent only moves forward after explicit confirmation from the worker that a phase is complete.
- Using one shared mutex + cond avoids per-thread busy-waiting while keeping the design simple.
- Shared memory is used to demonstrate `shmget`/`shmat` usage and allows the inspector to observe the segment with `ipcs -m` during the 10-second pause before cleanup.
- The code uses `pthread_cond_broadcast` (wake all) even though a single thread will act per phase; this is safe and simpler than tracking which thread to signal.

## Observability (how to inspect while it runs)

1. Run the program: `./a.out 5`.
2. Quickly run `ipcs -m` in another terminal to see the shared memory segment (shmid, owner, bytes, nattch).
3. While the program sleeps 10 seconds at the end, you can also run `ipcs -m` and `ipcs -m -t` to inspect timestamps.
4. Use `ipcrm -m <shmid>` to manually remove the segment if the program crashes (or just let program remove at cleanup).

## Potential issues & improvements

- The code uses a fixed key (1234) for `shmget` — collisions possible; consider using `ftok` for uniqueness.
- `pthread_mutex_t` and `pthread_cond_t` are placed in shared memory and initialized with default attributes. This generally works when the processes/threads share an address space, as here, but for multiple processes across different address spaces you'd need to set `PTHREAD_PROCESS_SHARED` attribute.
- There is no errno-checked error handling on `pthread_create`/`pthread_join`; adding checks would make the program more robust.
- `srand(time(NULL))` is called once in `main` — good. (If moved into loops, reseeding would be wrong.)
- The program uses `sleep(10)` to provide a window for `ipcs -m`. This is acceptable for lab demos but not ideal for production.

## Sample runs and expected output

- Valid invocation: `./a.out 5`
- Expected printed table format (see earlier example). For pairs where A==0, C prints `0.00`.

## Testing checklist

- [ ] Run `./a.out 1` ... `./a.out 10` to check edge conditions.
- [ ] Force a worker to sleep longer to test that parent waits correctly for `done[]` flags (introduce `usleep` in a worker for testing).
- [ ] Kill the program while it sleeps and ensure `ipcs -m` doesn't leave stale segments (inspect with `ipcs -m` and `ipcrm` if necessary).
- [ ] Change the shared-memory key to `IPC_PRIVATE` or a `ftok`-derived key to avoid collisions.

---

## Viva questions (with short model answers)

1. Q: Why use shared memory here instead of just passing data via global variables?
   - A: The assignment demonstrates System V IPC. Shared memory simulates inter-process communication where multiple processes can attach to the same memory region; it also allows `ipcs`/`ipcrm` inspection tools to be used.

2. Q: Why put the mutex and condition variable inside shared memory?
   - A: They live with the data they protect. If the program were extended to use multiple processes (not just threads) to access the segment, placing sync primitives in shared memory (and setting `PTHREAD_PROCESS_SHARED`) would be necessary.

3. Q: Why is `pthread_cond_broadcast` used instead of `pthread_cond_signal`?
   - A: `broadcast` wakes all waiting threads. It's simpler because the parent doesn't need to track which thread is waiting. Only the thread whose `phase` matches will act; others will go back to waiting.

4. Q: How does the parent ensure that the workers operate on the correct `idx` and don't race with each other?
   - A: The parent holds the mutex while updating `idx` and `phase`, and the workers check `phase` under the same mutex. Workers set `done[]` while still holding the mutex (or right after acquiring it), and the parent waits on `done[]` changes using the same mutex and condition variable — this preserves order and avoids races.

5. Q: What happens if `A` is zero? How is division by zero handled?
   - A: The code checks `if (a != 0)` before computing `c = (float)b / a`; otherwise `c` is set to `0.0`, preventing division-by-zero errors.

6. Q: Is placing mutexes/conds in shared memory always safe?
   - A: For threads within the same process it is safe. For inter-process synchronization via shared memory you must initialize with `pthread_mutexattr_setpshared(&attr, PTHREAD_PROCESS_SHARED)` (and the cond attr) so the kernel allows sharing across processes.

7. Q: Why does the parent sleep 10 seconds after printing?
   - A: To allow the user to run `ipcs -m` and observe the shared memory entry before the program removes it as part of cleanup.

8. Q: How would you modify the program to allow multiple producer processes or multiple consumer processes?
   - A: Move synchronization attributes to `PTHREAD_PROCESS_SHARED`, ensure all processes call `pthread_mutex_init`/`pthread_cond_init` with shared attributes (or the first creator does), and use robust ownership conventions for initialization and cleanup. Use robust error handling and a leader-election scheme to avoid double-destroying primitives.

9. Q: What are the pros/cons of using `pthread_cond_broadcast` with a single mutex for all phases versus separate per-thread condition variables?
   - A: Pros: simplicity and easier reasoning. Cons: extra wakeups (spurious wakeups to non-target threads) and slightly less efficient. Per-thread condvars can reduce spurious wakeups but add complexity.

10. Q: How would you make the program resilient to a worker thread crashing (not setting `done[]`)?
    - A: Use timeouts on condition waits (e.g., `pthread_cond_timedwait`) and add recovery logic; detect stalled workers and either retry the computation or abort gracefully and cleanup shared resources.

---

If you'd like, I can now:
- Add `A2_06_05_ARCH.md` (architecture, memory layout, Mermaid flowchart, sequence diagram) in the same folder (I will create it next).  
- Add small code robustness fixes to `question.c` (error checks on pthread calls, replace fixed shm key with `ftok`, or convert to contiguous memory layout).  

Say "create architecture doc" to proceed (or choose one of the robustness fixes to apply to the C source).